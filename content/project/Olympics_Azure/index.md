---
title:  "Azure Data Engineering Pipeline"
summary: End to end data pipeline using Azure 
tags:
  - Data Engineering
date: '2024-09-14T00:00:00Z'

# Optional external URL for project (replaces project detail page).
external_link: ''


links:
- icon: github
  icon_pack: fab
  name: Link
  url: https://github.com/rutvibheda/TokyoOlympics
  

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
# slides: example
---

In this project, I developed an end-to-end data pipeline using Azure Data Factory to automate the ingestion of raw Tokyo Olympics data into Azure Data Lake. This automation reduced manual data handling by 40%, streamlining the data ingestion process.

For data transformation, I utilized Azure Databricks, enabling scalable data processing and ensuring that the raw data was cleaned, enriched, and prepared for further analysis. The transformed data was then loaded into Azure Synapse Analytics, which significantly improved query performance and enabled advanced analytics.

Finally, I integrated Azure Synapse with visualization tools, enabling insightful reports and visualizations for stakeholders, enhancing decision-making with comprehensive and real-time analytical insights.